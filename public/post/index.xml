<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Shuai Shi` personal site</title>
    <link>https://shishuai.org/post/</link>
      <atom:link href="https://shishuai.org/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Tue, 21 Jan 2020 18:51:40 +0800</lastBuildDate>
    <image>
      <url>https://shishuai.org/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_2.png</url>
      <title>Posts</title>
      <link>https://shishuai.org/post/</link>
    </image>
    
    <item>
      <title>Bounds on number of cuts</title>
      <link>https://shishuai.org/post/2019-11-27-bounds-on-cuts/</link>
      <pubDate>Tue, 21 Jan 2020 18:51:40 +0800</pubDate>
      <guid>https://shishuai.org/post/2019-11-27-bounds-on-cuts/</guid>
      <description>&lt;p&gt;Recently there are some advances on counting the number of min-cut in graphs.&lt;/p&gt;
&lt;p&gt;Consider we have an undirected graph $G=(V,E)$ of $n$ vertices, and there are &lt;em&gt;positive&lt;/em&gt; cost $c:E\to \R^+$ on the edges. We define $c(F)=\sum_{e\in F}c(e)$, to be the cost (value) of $F\subset E$.&lt;/p&gt;
&lt;p&gt;Let $\mathcal{P}$ be a partition of $V$ where each partition class is non-empty. We define $E(\mathcal{P})$ to be the set of edges with end points in two different partition classes.
A set of edges $F$ is called a &lt;em&gt;$k$-cut&lt;/em&gt;, if $F=E(\mathcal{P})$ for some $\mathcal{P}$ such that $|\mathcal{P}|\geq k$.&lt;/p&gt;
&lt;p&gt;We stress that by this definition, a $k$-cut is a $k-1$-cut. A &lt;em&gt;cut&lt;/em&gt; is a $2$-cut. A min-$k$-cut is a $k$-cut of minimum value (cost). We let $\lambda_k$ to denote the value of the min-$k$-cut.&lt;/p&gt;
&lt;p&gt;It is well known that the number of min-cuts in a graph is ${n\choose 2} = O(n^2)$. [@KargerS96]&lt;/p&gt;
&lt;p&gt;In the entire article, unless specifically stated, we assume $k$ is a fixed integer at least $2$, and $\alpha$ is a fixed value at least $1$.&lt;/p&gt;
&lt;p&gt;We can express the state alternatively.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \lambda_2$ is $O(n^2)$.&lt;/p&gt;
&lt;h1 id=&#34;bounds-related-to-scaling-of-the-min-cut&#34;&gt;Bounds related to scaling of the min-cut&lt;/h1&gt;
&lt;p&gt;What happens when we want to know about the number of cuts with value at most $\alpha \lambda_2$?&lt;/p&gt;
&lt;p&gt;By simply analyzing Karger&#39;s algorithm, one can obtain the following.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \alpha \lambda_2$ is $O(n^{2\alpha})$.&lt;/p&gt;
&lt;p&gt;With more careful analysis using tree packing, Karger obtained the following [@Karger00].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \alpha \lambda_2$ is $O(n^{\floor{2\alpha}})$.&lt;/p&gt;
&lt;p&gt;Indeed, we do have a lower bound of ${n \choose \floor{2\alpha}}$. Just consider an unweighted cycle, where min-cut has value $2$. We can pick any $\floor{2\alpha}$ edges, which forms a cut of value at most $\alpha$ times the min-cut.&lt;/p&gt;
&lt;p&gt;Note that we require $\alpha$ to a fixed value. This is because there is a dependency on $\alpha$ hidden inside the big $O$. Our lower bound is absolute and does not depending on $\alpha$ being fixed. It be interesting to obtain a matching upper bound. Hence we can consider the problem with strict inequality.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;{.Conjecture #approxcutconjecture}&lt;/strong&gt; The number of cuts $F$ such that $c(F)&amp;lt; \alpha \lambda_2$ is $O(n^{\ceil{2\alpha}-1})$.&lt;/p&gt;
&lt;p&gt;Henzinger and Williamson showed the conjecture true for all $\alpha\leq \frac{3}{2}$ [@HenzingerW96].&lt;/p&gt;
&lt;h1 id=&#34;bounds-related-to-min-k-cut&#34;&gt;Bounds related to min-$k$-cut&lt;/h1&gt;
&lt;p&gt;There are multiple ways to obtain the following theorem. For example, directly generalize Karger&#39;s argument for cut counting.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \lambda_k$ is $O(n^{2(k-1)})$.&lt;/p&gt;
&lt;p&gt;There were many attempts, and people can only obtain lower bounds of the form ${n\choose k}$. Again, a cycle would be an example of such lower bound. The min-$k$-cut has value $k$, and can be obtained by picking any $k$ edges. The gap is pretty large. Hence one would tempt to conjecture the following.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;{.Conjecture #kcutconjecture}&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \lambda_k$ is $O(n^k)$.&lt;/p&gt;
&lt;p&gt;Recently, Gupta, Lee and Li almost closes the gap [@GuptaLL19].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \lambda_k$ is $\hat{O}(n^k)$.&lt;/p&gt;
&lt;p&gt;Here $\hat{O}$ hides a factor smaller than any $n^\epsilon$. While closing the gap, they showed thhe following interesting theorem.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \frac{(2-\epsilon)\lambda_k}{k}$ is $O(n)$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjecture&lt;/strong&gt; The number of cuts $F$ such that $c(F)&amp;lt; \frac{2\lambda_k}{k}$ is $O(n)$.&lt;/p&gt;
&lt;p&gt;Note this theorem is basically shows we can also obtain interesting results for $\alpha = \frac{2-\epsilon}{k} &amp;lt; 1$.&lt;/p&gt;
&lt;p&gt;How about approximate min-$k$-cuts? Chekuri, Quanrud and I extended the tree packing analysis of Karger, and obtained the following result for $k$-cuts [@ChekuriQX19].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c(F)\leq \alpha \lambda_k$ is $O(n^{\floor{\alpha 2(k-1)}})$.&lt;/p&gt;
&lt;p&gt;Combining the [@kcutconjecture] and [@approxcutconjecture], we get a unified conjecture, even for $\alpha&amp;lt;1$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjecture&lt;/strong&gt; The number of cuts $F$ such that $c(F)&amp;lt; \alpha \lambda_k$ is $O(n^{\ceil{\alpha k}-1})$.&lt;/p&gt;
&lt;h1 id=&#34;bounds-on-parametric-cuts&#34;&gt;Bounds on parametric cuts&lt;/h1&gt;
&lt;p&gt;Now, let&#39;s consider parametric cuts. Consider we have $d$ weight functions $c_1,\ldots,c_d:E\to \R_{\geq 0}$. Define $c_\mu(e) = \sum_{i=1}^d \mu_i c_i(e)$. We interested in knowing about cuts $F$ such that $c_\mu(F)$ is bounded by $\alpha \lambda_{\mu,k}$, where $\lambda_{\mu,k}$ is the min-$k$-cut value when the cost function is $c_\mu$.&lt;/p&gt;
&lt;p&gt;Karger showed the following [@Karger16].&lt;/p&gt;
&lt;p&gt;Hence, we would have the following conjecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjecture&lt;/strong&gt; The number of cuts $F$ such that $c_\mu(F)&amp;lt; \alpha \lambda_{\mu,k}$ for some $\mu\in \R_{\geq 0}^d$ is $O(n^{\ceil{\alpha k}+d-2})$.&lt;/p&gt;
&lt;p&gt;Note, we might relax the requirement that all $c_i$ and $\mu$ are non-negative. Aissi et. al. showed the following [@AissiMMQ15].&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of cuts $F$ such that $c_\mu(F)\leq \lambda_{\mu}$ for some $c_\mu\geq 0$ is $O(m^d n^2\log^{d-1} n)$.&lt;/p&gt;
&lt;p&gt;The following would be even stronger conjecture.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjecture&lt;/strong&gt; The number of cuts $F$ such that $c_\mu(F) &amp;lt; \alpha \lambda_{\mu,k}$ for some $c_\mu\geq 0$ is $O(n^{\ceil{\alpha k}+d-2})$.&lt;/p&gt;
&lt;h1 id=&#34;projected-cut-bounds&#34;&gt;Projected cut bounds&lt;/h1&gt;
&lt;p&gt;Let $\tau_e = \min_{U:e\in \delta(U)}c(\delta(U))$. Fung et. al. showed a projected generalization of the cut counting bound [@FungHHP19]. Let $E_\lambda = \set{ e | \tau_e \geq x }$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; The number of sets of the form $F\cap E_\lambda$ where $F$ is a cut such that $c(F)\leq \alpha \lambda$ is $O(n^{2\alpha})$.&lt;/p&gt;
&lt;p&gt;If we let $\lambda$ be the min-cut value, this is precisely the approximate cut counting bound.&lt;/p&gt;
&lt;p&gt;We can of course ask if all our theorem can be applied to projected cuts. We don&#39;t even know if it extends to $k$-cuts. However, we can expect the following ultimate conjecture.&lt;/p&gt;
&lt;p&gt;Let $\tau_{\mu,k,e}$ be the minimum over all $c_{\mu}(F)$, where $F$ is a $k$-cut containing $e$.
Let $E_{\mu,k,\lambda} = \set{e | \tau_{\mu,k,e} \geq \lambda}$.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Conjecture&lt;/strong&gt; The number of sets of the form $F\cap E_{\mu,k,\lambda}$ where $F$ is a cut such that $c_{\mu}(F)&amp;lt; \alpha \lambda$ for some $c_\mu\geq 0$ is $O(n^{\ceil{\alpha k}+d-2})$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>My First Post</title>
      <link>https://shishuai.org/post/my-first-post/</link>
      <pubDate>Tue, 21 Jan 2020 18:51:40 +0800</pubDate>
      <guid>https://shishuai.org/post/my-first-post/</guid>
      <description>&lt;p&gt;This problem is a generalization of the &lt;a href=&#34;https://leetcode.com/problems/word-break/&#34;&gt;word break&lt;/a&gt; problem on leetcode. Many algorithms you see online assumes that string in $W$ has constant length, checking the hash table takes $O(1)$ time, and obtain an $O(n^2)$ time algorithm. It is not as easy. Here we show an algorithm that considers the strings in $W$ have arbitrary length.&lt;/p&gt;
&lt;p&gt;Consider the following graph $G=(V,E)$, where $V=\set{0,\ldots,n}$, and there is an edge from $i$ and $j$, if $s[i+1..j]=w\in W$, and the label of the edge $(i,j)$ is the string $w$, and the cost is $c(w)$.
Let $z$ be number of substrings in $s$ matches some element in $W$. The graph has $z$ edges. Note $z=O(n\sqrt{L})$. Indeed, the sum of the length of the labels of all outgoing edges cannot be more than $L$, and the length of each label is different. Hence each vertex can have at most $O(\sqrt{L})$ outgoing edges. The graph is a DAG, so we can find the shortest path from $0$ to $n$ in linear time with respect to the number of edges.
This shows if we can compute the graph in $O(z+L)$ time, then we solve the problem in $O(z+L)$ time.&lt;/p&gt;
&lt;p&gt;We can build the Aho–Corasick automaton for $W$ in $O(L)$ time. It can be used to find all substrings of $s$ that matches something in $W$ by traversing the automaton once. The running time is the total number of substrings matched, which is $O(z)$. Hence building the graph takes $O(z+L)$ time.
$z$ is clearly no more than $nm$, where $m=|W|$. Also, it is also clear $z=O(n\sqrt{L})$. Indeed, there can be at most $O(\sqrt{L})$ edges start from $i$, since each edge has a label of different length, and sum of those length labels is no larger than $L$.&lt;/p&gt;
&lt;p&gt;If we only want to know if there exists a solution, then there is a $\tilde{O}(nL^{1/3}+L)$ time algorithm [@BringmannGL17]. The algorithm is close to optimal assuming the algorithm is combinatorial and the alphabet can be arbitrarily large.&lt;/p&gt;
&lt;p&gt;Can we obtain similar running time for the word break with cost problem? There are evidence against it. If the alphabet is unary, this problem is equivalent to the unbounded knapsack problem, which likely does not have an algorithm with running time $O((n+L)^{2-\e})$ for any $\e&amp;gt;0$ [@CyganMWW19] and $m$ can be as large as $\Omega(\sqrt{L})$. Of course, this does not mean there might not be a $O(nL^{1/3}+L)$ time algorithm, since the reduction involved in the paper might not hold when we require $m=\Omega(\sqrt{L})$.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Traditional vs Roth IRA under fixed amount of investment</title>
      <link>https://shishuai.org/post/2019-09-06-traditional-ira-vs-roth-ira/</link>
      <pubDate>Tue, 21 Jan 2020 18:51:40 +0800</pubDate>
      <guid>https://shishuai.org/post/2019-09-06-traditional-ira-vs-roth-ira/</guid>
      <description>&lt;p&gt;I&#39;ve read a lot of articles on Traditional vs Roth IRA. One can do a serious mathematical analysis of which one is better, given that you want to invest a total of $x$ income into the account for a particular year. Money in excess of $x$ will be put in a normal investment account.&lt;/p&gt;
&lt;p&gt;There is a widely held belief that if your effective tax rate is higher today than when you cash out, it is always better to do pre-tax contribution (Traditional IRA). However, we can show this is not always the case. You need effective tax rate to be somewhat lower unless you are in the lowest of tax bracket. Assume for simplicity, you don&#39;t have to pay state income tax.&lt;/p&gt;
&lt;p&gt;Assumption you way more than enough money to maximize the contribution.&lt;/p&gt;
&lt;p&gt;Here are the 3 options.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type 1: (Traditional IRA, 401(k)) No tax when contributing, taxed as ordinary income afterwards.&lt;/li&gt;
&lt;li&gt;Type 2: (Roth IRA, Roth 401(k)) Taxed when contributing, and no taxes with withdrawal.&lt;/li&gt;
&lt;li&gt;Type 3: Normal account, taxed when contributing, and tax with either ordinary income or capital gain taxes depending on type.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Consider the simplest model. You have a stock that you buy and hold. It generates no dividends. At the time when you sell it, it worths $k$ times more. All your money will be going into that stock.&lt;/p&gt;
&lt;p&gt;Assume you allocate $x$ income into $x_1,x_2,x_3$, which is the amount of income allocated into Type $1,2,3$ accounts, respectively.&lt;/p&gt;
&lt;p&gt;How much after tax income is generated when you sell the stock?&lt;/p&gt;
&lt;p&gt;Let $\alpha$ be the (approximate) effective tax rate today, $\alpha&#39;$ is an (approximate) effective tax rate when you sell. $\beta&#39;$ is the capital gain tax rate.&lt;/p&gt;
&lt;p&gt;The after-tax income contributed by each account is&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type 1: $kx_1(1-\alpha&amp;rsquo;)$&lt;/li&gt;
&lt;li&gt;Type 2: $kx_2(1-\alpha)$&lt;/li&gt;
&lt;li&gt;Type 3: $(k-1)x_3(1-\alpha)(1-\beta&amp;rsquo;) + x_3(1-\alpha)$ $= x_3(1-\alpha)((k-1)(1-\beta&amp;rsquo;)+1)$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, we also have the following constraint. $x_1+x_2(1-\alpha)=B$, where $B$ is the maximum contribution into type 1 and type 2 accounts. This happens because they share the same bound (this is true for both 401(k) and IRA). Note that $x_1+x_2+x_3=x$. Since $B$ and $x$ are fixed, we have $x_2 = \frac{B-x_1}{1-\alpha}$, and $x_3 = x-x_1-\frac{B-x_1}{1-\alpha}$&lt;/p&gt;
&lt;p&gt;Define $f(x_1)=kx_1(1-\alpha&amp;rsquo;) + k(B-x_1) + $$(x-x_1-\frac{B-x_1}{1-\alpha})(1-\alpha)((k-1)(1-\beta&amp;rsquo;)+1)$, which is a linear function. We take the derivative of $f$ and obtain the slope if $k(\alpha-\alpha&amp;rsquo;)- (k-1)\alpha\beta&#39;$. If the slope is positive, it means when should maximize type $1$ account, and if the slope is negative, we should maximize type $2$ account.&lt;/p&gt;
&lt;p&gt;In order for the inequality to work for all $k&amp;gt;1$, we need $\alpha-\alpha&amp;rsquo;\geq \alpha\beta&#39;$.
In other words, we need $\alpha&amp;rsquo;\leq \alpha(1-\beta&amp;rsquo;)$ in order to safely say it is better to maximize type 1.&lt;/p&gt;
&lt;p&gt;We didn&#39;t even consider what happens if there are dividend involved. It would shift the scale even more toward type 2.&lt;/p&gt;
&lt;p&gt;I think the moral of the story is you have to be careful and actually model everything correctly. Also, since there is no way to know the tax rate in the future, some people hedge the risk by putting money in both type 1 and type 2 accounts.&lt;/p&gt;
&lt;p&gt;It looks like this still suggest putting money in Traditional IRA is better than Roth IRA if your current tax rate is &lt;em&gt;much higher&lt;/em&gt; than your future tax rate.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Word break with cost</title>
      <link>https://shishuai.org/post/2019-09-19-word-break-with-cost/</link>
      <pubDate>Tue, 21 Jan 2020 18:51:40 +0800</pubDate>
      <guid>https://shishuai.org/post/2019-09-19-word-break-with-cost/</guid>
      <description>&lt;p&gt;This problem is a generalization of the &lt;a href=&#34;https://leetcode.com/problems/word-break/&#34;&gt;word break&lt;/a&gt; problem on leetcode. Many algorithms you see online assumes that string in $W$ has constant length, checking the hash table takes $O(1)$ time, and obtain an $O(n^2)$ time algorithm. It is not as easy. Here we show an algorithm that considers the strings in $W$ have arbitrary length.&lt;/p&gt;
&lt;p&gt;Consider the following graph $G=(V,E)$, where $V=\set{0,\ldots,n}$, and there is an edge from $i$ and $j$, if $s[i+1..j]=w\in W$, and the label of the edge $(i,j)$ is the string $w$, and the cost is $c(w)$.
Let $z$ be number of substrings in $s$ matches some element in $W$. The graph has $z$ edges. Note $z=O(n\sqrt{L})$. Indeed, the sum of the length of the labels of all outgoing edges cannot be more than $L$, and the length of each label is different. Hence each vertex can have at most $O(\sqrt{L})$ outgoing edges. The graph is a DAG, so we can find the shortest path from $0$ to $n$ in linear time with respect to the number of edges.
This shows if we can compute the graph in $O(z+L)$ time, then we solve the problem in $O(z+L)$ time.&lt;/p&gt;
&lt;p&gt;We can build the Aho–Corasick automaton for $W$ in $O(L)$ time. It can be used to find all substrings of $s$ that matches something in $W$ by traversing the automaton once. The running time is the total number of substrings matched, which is $O(z)$. Hence building the graph takes $O(z+L)$ time.
$z$ is clearly no more than $nm$, where $m=|W|$. Also, it is also clear $z=O(n\sqrt{L})$. Indeed, there can be at most $O(\sqrt{L})$ edges start from $i$, since each edge has a label of different length, and sum of those length labels is no larger than $L$.&lt;/p&gt;
&lt;p&gt;If we only want to know if there exists a solution, then there is a $\tilde{O}(nL^{1/3}+L)$ time algorithm [@BringmannGL17]. The algorithm is close to optimal assuming the algorithm is combinatorial and the alphabet can be arbitrarily large.&lt;/p&gt;
&lt;p&gt;Can we obtain similar running time for the word break with cost problem? There are evidence against it. If the alphabet is unary, this problem is equivalent to the unbounded knapsack problem, which likely does not have an algorithm with running time $O((n+L)^{2-\e})$ for any $\e&amp;gt;0$ [@CyganMWW19] and $m$ can be as large as $\Omega(\sqrt{L})$. Of course, this does not mean there might not be a $O(nL^{1/3}+L)$ time algorithm, since the reduction involved in the paper might not hold when we require $m=\Omega(\sqrt{L})$.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
